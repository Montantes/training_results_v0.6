Beginning trial 1 of 1
Gathering sys log on lambda-server
:::MLL 1572948761.894 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1572948761.895 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1572948761.896 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1572948761.897 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1572948761.897 submission_platform: {"value": "1xSYS-4029GP-TRT", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1572948761.898 submission_entry: {"value": "{'hardware': 'SYS-4029GP-TRT', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': ' ', 'os': 'Ubuntu 18.04.3 LTS / ', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-1.0.0', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '1', 'cpu': '2x Intel(R) Xeon(R) Silver 4116 CPU @ 2.10GHz', 'num_cores': '24', 'num_vcpus': '48', 'accelerator': 'GeForce RTX 2080 Ti', 'num_accelerators': '8', 'sys_mem_size': '503 GB', 'sys_storage_type': 'SATA SSD', 'sys_storage_size': '1x 3.7T', 'cpu_accel_interconnect': 'UPI', 'network_card': '', 'num_network_cards': '0', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1572948761.899 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1572948761.899 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
:::MLL 1572948774.319 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node lambda-server
+ pids+=($!)
+ set +x
++ eval echo
+++ echo
+ docker exec -e DGXSYSTEM=LambdaBlade2080Ti -e 'MULTI_NODE= --master_port=5180' -e SLURM_JOB_ID=191105021201507477811 -e SLURM_NTASKS_PER_NODE= cont_191105021201507477811 ./run_and_time.sh
Run vars: id 191105021201507477811 gpus 8 mparams  --master_port=5180
STARTING TIMING RUN AT 2019-11-05 10:12:55 AM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 12 --nproc_per_node 8 --master_port=5180 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 120 --eval-batch-size 160 --warmup 650 --lr 2.92e-3 --wd 1.6e-4 --use-nvjpeg --use-roi-decode
:::MLL 1572948781.746 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572948781.747 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572948781.748 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572948781.748 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
BN group: 1
:::MLL 1572948781.752 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572948781.754 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572948781.755 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
:::MLL 1572948781.756 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
6 Using seed = 3794568323
5 Using seed = 3794568322
7 Using seed = 3794568324
4 Using seed = 3794568321
2 Using seed = 3794568319
1 Using seed = 3794568318
3 Using seed = 3794568320
0 Using seed = 3794568317
:::MLL 1572948790.414 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1572948791.205 model_bn_span: {"value": 120, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1572948791.206 global_batch_size: {"value": 960, "metadata": {"file": "train.py", "lineno": 481}}
:::MLL 1572948791.231 opt_base_learning_rate: {"value": 0.08750000000000001, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1572948791.232 opt_weight_decay: {"value": 0.00016, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1572948791.232 opt_learning_rate_warmup_steps: {"value": 650, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1572948791.233 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
epoch nbatch loss
:::MLL 1572948798.576 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1572948798.577 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.56s)
creating index...
Done (t=0.56s)
creating index...
Done (t=0.57s)
creating index...
Done (t=0.61s)
creating index...
Done (t=0.61s)
creating index...
Done (t=0.62s)
creating index...
Done (t=0.62s)
creating index...
Done (t=0.63s)
creating index...
time_check a: 1572948800.766149998
time_check b: 1572948806.046314478
:::MLL 1572948807.139 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1572948807.141 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.379, Average Loss: 0.022, avg. samples / sec: 58.07
Iteration:     20, Loss function: 20.607, Average Loss: 0.441, avg. samples / sec: 2394.67
Iteration:     40, Loss function: 17.575, Average Loss: 0.827, avg. samples / sec: 2606.40
Iteration:     60, Loss function: 12.586, Average Loss: 1.081, avg. samples / sec: 2603.75
Iteration:     80, Loss function: 9.889, Average Loss: 1.276, avg. samples / sec: 2603.36
Iteration:    100, Loss function: 9.608, Average Loss: 1.443, avg. samples / sec: 2599.35
Iteration:    120, Loss function: 8.868, Average Loss: 1.594, avg. samples / sec: 2605.48
:::MLL 1572948854.329 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1572948854.329 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 9.201, Average Loss: 1.736, avg. samples / sec: 2608.45
Iteration:    160, Loss function: 8.461, Average Loss: 1.873, avg. samples / sec: 2605.75
Iteration:    180, Loss function: 8.360, Average Loss: 2.001, avg. samples / sec: 2603.32
Iteration:    200, Loss function: 8.152, Average Loss: 2.127, avg. samples / sec: 2599.35
Iteration:    220, Loss function: 7.622, Average Loss: 2.244, avg. samples / sec: 2601.69
Iteration:    240, Loss function: 7.808, Average Loss: 2.355, avg. samples / sec: 2602.80
:::MLL 1572948899.331 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1572948899.332 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    260, Loss function: 7.628, Average Loss: 2.459, avg. samples / sec: 2589.93
Iteration:    280, Loss function: 7.366, Average Loss: 2.561, avg. samples / sec: 2607.07
Iteration:    300, Loss function: 7.028, Average Loss: 2.656, avg. samples / sec: 2599.52
Iteration:    320, Loss function: 7.283, Average Loss: 2.748, avg. samples / sec: 2598.92
Iteration:    340, Loss function: 7.086, Average Loss: 2.835, avg. samples / sec: 2599.66
Iteration:    360, Loss function: 7.037, Average Loss: 2.919, avg. samples / sec: 2600.90
:::MLL 1572948944.389 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1572948944.389 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    380, Loss function: 7.022, Average Loss: 3.001, avg. samples / sec: 2583.29
Iteration:    400, Loss function: 6.759, Average Loss: 3.075, avg. samples / sec: 2588.27
Iteration:    420, Loss function: 6.333, Average Loss: 3.143, avg. samples / sec: 2598.16
Iteration:    440, Loss function: 7.301, Average Loss: 3.216, avg. samples / sec: 2594.30
Iteration:    460, Loss function: 6.478, Average Loss: 3.289, avg. samples / sec: 2587.26
Iteration:    480, Loss function: 6.536, Average Loss: 3.353, avg. samples / sec: 2600.16
:::MLL 1572948989.569 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1572948989.569 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 5.913, Average Loss: 3.413, avg. samples / sec: 2594.48
Iteration:    520, Loss function: 6.005, Average Loss: 3.468, avg. samples / sec: 2594.07
Iteration:    540, Loss function: 5.762, Average Loss: 3.519, avg. samples / sec: 2590.19
Iteration:    560, Loss function: 5.930, Average Loss: 3.572, avg. samples / sec: 2584.78
Iteration:    580, Loss function: 6.029, Average Loss: 3.621, avg. samples / sec: 2589.48
Iteration:    600, Loss function: 5.774, Average Loss: 3.667, avg. samples / sec: 2595.34
:::MLL 1572949034.771 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1572949034.772 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    620, Loss function: 5.751, Average Loss: 3.712, avg. samples / sec: 2586.97
Iteration:    640, Loss function: 6.006, Average Loss: 3.755, avg. samples / sec: 2591.81
Iteration:    660, Loss function: 5.735, Average Loss: 3.795, avg. samples / sec: 2588.54
Iteration:    680, Loss function: 5.747, Average Loss: 3.833, avg. samples / sec: 2598.10
Iteration:    700, Loss function: 5.469, Average Loss: 3.867, avg. samples / sec: 2592.04
Iteration:    720, Loss function: 5.739, Average Loss: 3.899, avg. samples / sec: 2597.44
:::MLL 1572949079.960 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1572949079.960 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    740, Loss function: 5.576, Average Loss: 3.933, avg. samples / sec: 2582.35
Iteration:    760, Loss function: 5.565, Average Loss: 3.962, avg. samples / sec: 2594.39
Iteration:    780, Loss function: 5.452, Average Loss: 3.990, avg. samples / sec: 2598.53
Iteration:    800, Loss function: 5.305, Average Loss: 4.015, avg. samples / sec: 2600.22
Iteration:    820, Loss function: 5.356, Average Loss: 4.041, avg. samples / sec: 2595.10
Iteration:    840, Loss function: 5.453, Average Loss: 4.067, avg. samples / sec: 2592.88
:::MLL 1572949125.470 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1572949125.470 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    860, Loss function: 5.130, Average Loss: 4.090, avg. samples / sec: 2584.20
Iteration:    880, Loss function: 5.296, Average Loss: 4.110, avg. samples / sec: 2600.40
Iteration:    900, Loss function: 5.386, Average Loss: 4.132, avg. samples / sec: 2599.65
Iteration:    920, Loss function: 5.254, Average Loss: 4.153, avg. samples / sec: 2590.54
Iteration:    940, Loss function: 5.002, Average Loss: 4.173, avg. samples / sec: 2594.52
Iteration:    960, Loss function: 5.013, Average Loss: 4.190, avg. samples / sec: 2588.55
:::MLL 1572949170.615 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1572949170.615 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 4.735, Average Loss: 4.206, avg. samples / sec: 2597.84
Iteration:   1000, Loss function: 5.118, Average Loss: 4.222, avg. samples / sec: 2592.69
Iteration:   1020, Loss function: 5.027, Average Loss: 4.237, avg. samples / sec: 2602.30
Iteration:   1040, Loss function: 4.753, Average Loss: 4.250, avg. samples / sec: 2595.62
Iteration:   1060, Loss function: 4.819, Average Loss: 4.264, avg. samples / sec: 2591.08
Iteration:   1080, Loss function: 4.728, Average Loss: 4.276, avg. samples / sec: 2598.44
:::MLL 1572949215.744 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1572949215.745 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:   1100, Loss function: 4.808, Average Loss: 4.291, avg. samples / sec: 2590.88
Iteration:   1120, Loss function: 5.124, Average Loss: 4.301, avg. samples / sec: 2602.09
Iteration:   1140, Loss function: 5.007, Average Loss: 4.309, avg. samples / sec: 2598.20
Iteration:   1160, Loss function: 4.862, Average Loss: 4.318, avg. samples / sec: 2600.91
Iteration:   1180, Loss function: 4.842, Average Loss: 4.328, avg. samples / sec: 2596.69
Iteration:   1200, Loss function: 4.683, Average Loss: 4.337, avg. samples / sec: 2597.91
Iteration:   1220, Loss function: 4.672, Average Loss: 4.345, avg. samples / sec: 2602.24
:::MLL 1572949260.823 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1572949260.824 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:   1240, Loss function: 4.547, Average Loss: 4.351, avg. samples / sec: 2591.59
Iteration:   1260, Loss function: 4.586, Average Loss: 4.358, avg. samples / sec: 2592.02
Iteration:   1280, Loss function: 4.710, Average Loss: 4.364, avg. samples / sec: 2598.36
Iteration:   1300, Loss function: 4.687, Average Loss: 4.370, avg. samples / sec: 2602.41
Iteration:   1320, Loss function: 4.855, Average Loss: 4.378, avg. samples / sec: 2600.24
Iteration:   1340, Loss function: 4.724, Average Loss: 4.383, avg. samples / sec: 2601.41
:::MLL 1572949305.904 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1572949305.905 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:   1360, Loss function: 4.883, Average Loss: 4.388, avg. samples / sec: 2596.72
Iteration:   1380, Loss function: 4.353, Average Loss: 4.393, avg. samples / sec: 2604.05
Iteration:   1400, Loss function: 4.320, Average Loss: 4.397, avg. samples / sec: 2597.55
Iteration:   1420, Loss function: 4.626, Average Loss: 4.401, avg. samples / sec: 2592.26
Iteration:   1440, Loss function: 4.715, Average Loss: 4.406, avg. samples / sec: 2595.29
Iteration:   1460, Loss function: 4.652, Average Loss: 4.410, avg. samples / sec: 2596.62
:::MLL 1572949350.988 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1572949350.989 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.496, Average Loss: 4.412, avg. samples / sec: 2599.41
Iteration:   1500, Loss function: 4.476, Average Loss: 4.413, avg. samples / sec: 2603.10
Iteration:   1520, Loss function: 4.499, Average Loss: 4.414, avg. samples / sec: 2600.41
Iteration:   1540, Loss function: 4.446, Average Loss: 4.415, avg. samples / sec: 2599.45
Iteration:   1560, Loss function: 4.505, Average Loss: 4.417, avg. samples / sec: 2588.83
Iteration:   1580, Loss function: 4.303, Average Loss: 4.420, avg. samples / sec: 2590.54
:::MLL 1572949396.099 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1572949396.099 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:   1600, Loss function: 4.557, Average Loss: 4.420, avg. samples / sec: 2590.06
Iteration:   1620, Loss function: 4.327, Average Loss: 4.422, avg. samples / sec: 2597.20
Iteration:   1640, Loss function: 4.506, Average Loss: 4.422, avg. samples / sec: 2601.74
Iteration:   1660, Loss function: 4.151, Average Loss: 4.422, avg. samples / sec: 2590.10
Iteration:   1680, Loss function: 4.251, Average Loss: 4.424, avg. samples / sec: 2597.12
Iteration:   1700, Loss function: 4.295, Average Loss: 4.425, avg. samples / sec: 2590.17
:::MLL 1572949441.608 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1572949441.608 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:   1720, Loss function: 4.387, Average Loss: 4.425, avg. samples / sec: 2591.38
Iteration:   1740, Loss function: 4.412, Average Loss: 4.423, avg. samples / sec: 2595.92
Iteration:   1760, Loss function: 4.546, Average Loss: 4.423, avg. samples / sec: 2603.14
Iteration:   1780, Loss function: 4.395, Average Loss: 4.424, avg. samples / sec: 2597.84
Iteration:   1800, Loss function: 4.381, Average Loss: 4.423, avg. samples / sec: 2594.19
Iteration:   1820, Loss function: 4.575, Average Loss: 4.425, avg. samples / sec: 2595.93
:::MLL 1572949486.731 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1572949486.732 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1840, Loss function: 4.334, Average Loss: 4.424, avg. samples / sec: 2591.99
Iteration:   1860, Loss function: 4.329, Average Loss: 4.422, avg. samples / sec: 2597.85
Iteration:   1880, Loss function: 4.643, Average Loss: 4.420, avg. samples / sec: 2591.02
Iteration:   1900, Loss function: 4.474, Average Loss: 4.419, avg. samples / sec: 2595.89
Iteration:   1920, Loss function: 4.444, Average Loss: 4.418, avg. samples / sec: 2593.38
Iteration:   1940, Loss function: 4.491, Average Loss: 4.415, avg. samples / sec: 2604.21
:::MLL 1572949531.837 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1572949531.838 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.308, Average Loss: 4.411, avg. samples / sec: 2591.70
Iteration:   1980, Loss function: 4.348, Average Loss: 4.409, avg. samples / sec: 2596.45
Iteration:   2000, Loss function: 4.535, Average Loss: 4.407, avg. samples / sec: 2584.86
Iteration:   2020, Loss function: 4.359, Average Loss: 4.406, avg. samples / sec: 2594.86
Iteration:   2040, Loss function: 4.111, Average Loss: 4.404, avg. samples / sec: 2598.24
Iteration:   2060, Loss function: 4.296, Average Loss: 4.400, avg. samples / sec: 2595.48
:::MLL 1572949576.991 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1572949576.992 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   2080, Loss function: 4.350, Average Loss: 4.397, avg. samples / sec: 2593.65
Iteration:   2100, Loss function: 4.313, Average Loss: 4.395, avg. samples / sec: 2603.42
Iteration:   2120, Loss function: 4.493, Average Loss: 4.392, avg. samples / sec: 2601.34
Iteration:   2140, Loss function: 4.072, Average Loss: 4.389, avg. samples / sec: 2603.69
Iteration:   2160, Loss function: 4.501, Average Loss: 4.387, avg. samples / sec: 2606.37
Iteration:   2180, Loss function: 4.187, Average Loss: 4.384, avg. samples / sec: 2603.26
:::MLL 1572949622.035 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1572949622.036 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   2200, Loss function: 4.310, Average Loss: 4.380, avg. samples / sec: 2583.15
Iteration:   2220, Loss function: 3.988, Average Loss: 4.377, avg. samples / sec: 2586.76
Iteration:   2240, Loss function: 4.205, Average Loss: 4.373, avg. samples / sec: 2598.55
Iteration:   2260, Loss function: 4.472, Average Loss: 4.369, avg. samples / sec: 2604.31
Iteration:   2280, Loss function: 4.215, Average Loss: 4.367, avg. samples / sec: 2594.63
Iteration:   2300, Loss function: 4.441, Average Loss: 4.365, avg. samples / sec: 2594.24
Iteration:   2320, Loss function: 4.438, Average Loss: 4.362, avg. samples / sec: 2594.82
:::MLL 1572949667.168 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1572949667.169 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   2340, Loss function: 3.990, Average Loss: 4.357, avg. samples / sec: 2596.61
Iteration:   2360, Loss function: 3.988, Average Loss: 4.353, avg. samples / sec: 2592.64
Iteration:   2380, Loss function: 4.173, Average Loss: 4.349, avg. samples / sec: 2601.05
Iteration:   2400, Loss function: 4.309, Average Loss: 4.345, avg. samples / sec: 2597.90
Iteration:   2420, Loss function: 3.985, Average Loss: 4.341, avg. samples / sec: 2598.91
Iteration:   2440, Loss function: 4.148, Average Loss: 4.338, avg. samples / sec: 2600.32
:::MLL 1572949712.627 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1572949712.627 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.176, Average Loss: 4.334, avg. samples / sec: 2585.75
Iteration:   2480, Loss function: 4.079, Average Loss: 4.330, avg. samples / sec: 2594.00
Iteration:   2500, Loss function: 4.443, Average Loss: 4.326, avg. samples / sec: 2601.66
Iteration:   2520, Loss function: 4.093, Average Loss: 4.321, avg. samples / sec: 2602.58
Iteration:   2540, Loss function: 4.144, Average Loss: 4.318, avg. samples / sec: 2603.03
Iteration:   2560, Loss function: 4.253, Average Loss: 4.314, avg. samples / sec: 2591.99
:::MLL 1572949757.738 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1572949757.738 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   2580, Loss function: 4.179, Average Loss: 4.310, avg. samples / sec: 2585.45
Iteration:   2600, Loss function: 4.053, Average Loss: 4.306, avg. samples / sec: 2590.58
Iteration:   2620, Loss function: 3.967, Average Loss: 4.300, avg. samples / sec: 2592.45
Iteration:   2640, Loss function: 3.895, Average Loss: 4.296, avg. samples / sec: 2596.60
Iteration:   2660, Loss function: 4.073, Average Loss: 4.291, avg. samples / sec: 2596.72
Iteration:   2680, Loss function: 3.704, Average Loss: 4.287, avg. samples / sec: 2601.23
:::MLL 1572949802.878 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1572949802.879 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   2700, Loss function: 4.104, Average Loss: 4.283, avg. samples / sec: 2587.30
Iteration:   2720, Loss function: 3.872, Average Loss: 4.279, avg. samples / sec: 2590.67
Iteration:   2740, Loss function: 3.964, Average Loss: 4.276, avg. samples / sec: 2595.01
Iteration:   2760, Loss function: 4.253, Average Loss: 4.273, avg. samples / sec: 2583.18
Iteration:   2780, Loss function: 3.979, Average Loss: 4.269, avg. samples / sec: 2593.10
Iteration:   2800, Loss function: 4.037, Average Loss: 4.265, avg. samples / sec: 2591.00
:::MLL 1572949848.119 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1572949848.120 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   2820, Loss function: 3.891, Average Loss: 4.261, avg. samples / sec: 2581.09
Iteration:   2840, Loss function: 3.863, Average Loss: 4.256, avg. samples / sec: 2600.94
Iteration:   2860, Loss function: 3.715, Average Loss: 4.251, avg. samples / sec: 2596.06
Iteration:   2880, Loss function: 3.776, Average Loss: 4.247, avg. samples / sec: 2600.97
Iteration:   2900, Loss function: 4.162, Average Loss: 4.244, avg. samples / sec: 2596.35
Iteration:   2920, Loss function: 4.067, Average Loss: 4.241, avg. samples / sec: 2587.55
:::MLL 1572949893.254 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1572949893.254 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.947, Average Loss: 4.237, avg. samples / sec: 2595.20
Iteration:   2960, Loss function: 4.252, Average Loss: 4.232, avg. samples / sec: 2597.88
Iteration:   2980, Loss function: 3.854, Average Loss: 4.228, avg. samples / sec: 2597.89
Iteration:   3000, Loss function: 4.198, Average Loss: 4.224, avg. samples / sec: 2592.79
Iteration:   3020, Loss function: 4.285, Average Loss: 4.220, avg. samples / sec: 2603.52
Iteration:   3040, Loss function: 4.001, Average Loss: 4.216, avg. samples / sec: 2592.06
:::MLL 1572949938.357 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1572949938.358 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   3060, Loss function: 3.970, Average Loss: 4.213, avg. samples / sec: 2593.57
Iteration:   3080, Loss function: 3.943, Average Loss: 4.208, avg. samples / sec: 2595.50
Iteration:   3100, Loss function: 3.950, Average Loss: 4.203, avg. samples / sec: 2590.49
Iteration:   3120, Loss function: 3.973, Average Loss: 4.198, avg. samples / sec: 2596.32
Iteration:   3140, Loss function: 4.123, Average Loss: 4.195, avg. samples / sec: 2597.98
Iteration:   3160, Loss function: 3.916, Average Loss: 4.191, avg. samples / sec: 2594.97
:::MLL 1572949983.485 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1572949983.485 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   3180, Loss function: 4.231, Average Loss: 4.186, avg. samples / sec: 2596.32
Iteration:   3200, Loss function: 4.210, Average Loss: 4.183, avg. samples / sec: 2600.56
Iteration:   3220, Loss function: 3.899, Average Loss: 4.178, avg. samples / sec: 2595.20
Iteration:   3240, Loss function: 4.048, Average Loss: 4.174, avg. samples / sec: 2588.33
Iteration:   3260, Loss function: 4.044, Average Loss: 4.169, avg. samples / sec: 2589.98
Iteration:   3280, Loss function: 4.003, Average Loss: 4.165, avg. samples / sec: 2594.71
:::MLL 1572950029.011 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1572950029.012 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 4.060, Average Loss: 4.163, avg. samples / sec: 2592.76
Iteration:   3320, Loss function: 3.876, Average Loss: 4.159, avg. samples / sec: 2590.91
Iteration:   3340, Loss function: 4.035, Average Loss: 4.155, avg. samples / sec: 2599.98
Iteration:   3360, Loss function: 3.942, Average Loss: 4.152, avg. samples / sec: 2592.42
Iteration:   3380, Loss function: 3.894, Average Loss: 4.149, avg. samples / sec: 2594.16
Iteration:   3400, Loss function: 3.912, Average Loss: 4.145, avg. samples / sec: 2598.58
Iteration:   3420, Loss function: 3.830, Average Loss: 4.142, avg. samples / sec: 2593.35
:::MLL 1572950074.160 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1572950074.160 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.749, Average Loss: 4.137, avg. samples / sec: 2591.30
Iteration:   3460, Loss function: 4.203, Average Loss: 4.134, avg. samples / sec: 2596.52
Iteration:   3480, Loss function: 4.309, Average Loss: 4.131, avg. samples / sec: 2592.14
Iteration:   3500, Loss function: 3.960, Average Loss: 4.127, avg. samples / sec: 2594.04
Iteration:   3520, Loss function: 3.735, Average Loss: 4.123, avg. samples / sec: 2590.90
Iteration:   3540, Loss function: 4.024, Average Loss: 4.118, avg. samples / sec: 2596.25
:::MLL 1572950119.316 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1572950119.317 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 4.046, Average Loss: 4.114, avg. samples / sec: 2593.28
Iteration:   3580, Loss function: 3.997, Average Loss: 4.109, avg. samples / sec: 2590.27
Iteration:   3600, Loss function: 3.756, Average Loss: 4.106, avg. samples / sec: 2604.51
Iteration:   3620, Loss function: 3.843, Average Loss: 4.104, avg. samples / sec: 2595.83
Iteration:   3640, Loss function: 3.947, Average Loss: 4.102, avg. samples / sec: 2594.59
Iteration:   3660, Loss function: 3.559, Average Loss: 4.098, avg. samples / sec: 2602.27
:::MLL 1572950164.418 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1572950164.419 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   3680, Loss function: 4.087, Average Loss: 4.094, avg. samples / sec: 2596.72
Iteration:   3700, Loss function: 3.924, Average Loss: 4.091, avg. samples / sec: 2597.42
Iteration:   3720, Loss function: 3.957, Average Loss: 4.086, avg. samples / sec: 2593.54
Iteration:   3740, Loss function: 3.865, Average Loss: 4.083, avg. samples / sec: 2591.85
Iteration:   3760, Loss function: 3.838, Average Loss: 4.079, avg. samples / sec: 2590.39
Iteration:   3780, Loss function: 3.826, Average Loss: 4.075, avg. samples / sec: 2597.23
:::MLL 1572950209.555 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1572950209.556 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   3800, Loss function: 3.770, Average Loss: 4.071, avg. samples / sec: 2599.70
Iteration:   3820, Loss function: 4.192, Average Loss: 4.068, avg. samples / sec: 2599.95
Iteration:   3840, Loss function: 4.030, Average Loss: 4.065, avg. samples / sec: 2598.95
Iteration:   3860, Loss function: 3.711, Average Loss: 4.062, avg. samples / sec: 2600.52
Iteration:   3880, Loss function: 3.816, Average Loss: 4.058, avg. samples / sec: 2596.39
Iteration:   3900, Loss function: 3.830, Average Loss: 4.057, avg. samples / sec: 2596.19
:::MLL 1572950254.625 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1572950254.625 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 3.948, Average Loss: 4.055, avg. samples / sec: 2601.78
Iteration:   3940, Loss function: 3.844, Average Loss: 4.052, avg. samples / sec: 2597.43
Iteration:   3960, Loss function: 3.957, Average Loss: 4.047, avg. samples / sec: 2595.66
Iteration:   3980, Loss function: 3.791, Average Loss: 4.043, avg. samples / sec: 2591.60
Iteration:   4000, Loss function: 4.023, Average Loss: 4.038, avg. samples / sec: 2598.07
:::MLL 1572950288.643 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 8.55 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.41s)
DONE (t=0.42s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.42s)
DONE (t=2.81s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.18296
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33555
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.18473
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04853
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.19129
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.29314
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.19109
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27975
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29442
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08355
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31271
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.45665
Current AP: 0.18296 AP goal: 0.23000
:::MLL 1572950300.484 eval_accuracy: {"value": 0.18296168273966834, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1572950300.493 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1572950300.528 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1572950300.529 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   4020, Loss function: 3.804, Average Loss: 4.035, avg. samples / sec: 985.00
:::MLL 1572950312.178 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1572950312.178 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   4040, Loss function: 3.966, Average Loss: 4.033, avg. samples / sec: 2599.55
Iteration:   4060, Loss function: 4.039, Average Loss: 4.029, avg. samples / sec: 2606.88
Iteration:   4080, Loss function: 3.821, Average Loss: 4.026, avg. samples / sec: 2613.11
Iteration:   4100, Loss function: 3.817, Average Loss: 4.023, avg. samples / sec: 2603.64
Iteration:   4120, Loss function: 3.947, Average Loss: 4.020, avg. samples / sec: 2590.16
Iteration:   4140, Loss function: 3.929, Average Loss: 4.018, avg. samples / sec: 2600.53
:::MLL 1572950357.219 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1572950357.220 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   4160, Loss function: 3.574, Average Loss: 4.015, avg. samples / sec: 2589.67
Iteration:   4180, Loss function: 4.183, Average Loss: 4.011, avg. samples / sec: 2598.64
Iteration:   4200, Loss function: 3.846, Average Loss: 4.008, avg. samples / sec: 2596.85
Iteration:   4220, Loss function: 3.915, Average Loss: 4.005, avg. samples / sec: 2587.83
Iteration:   4240, Loss function: 3.807, Average Loss: 4.002, avg. samples / sec: 2592.39
Iteration:   4260, Loss function: 3.894, Average Loss: 3.999, avg. samples / sec: 2590.39
:::MLL 1572950402.403 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1572950402.404 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   4280, Loss function: 3.780, Average Loss: 3.997, avg. samples / sec: 2586.27
Iteration:   4300, Loss function: 3.860, Average Loss: 3.993, avg. samples / sec: 2594.24
Iteration:   4320, Loss function: 3.962, Average Loss: 3.989, avg. samples / sec: 2598.40
Iteration:   4340, Loss function: 3.834, Average Loss: 3.985, avg. samples / sec: 2597.86
Iteration:   4360, Loss function: 3.763, Average Loss: 3.982, avg. samples / sec: 2584.78
Iteration:   4380, Loss function: 3.925, Average Loss: 3.979, avg. samples / sec: 2587.79
:::MLL 1572950447.583 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1572950447.584 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   4400, Loss function: 3.773, Average Loss: 3.976, avg. samples / sec: 2588.12
Iteration:   4420, Loss function: 3.991, Average Loss: 3.974, avg. samples / sec: 2595.64
Iteration:   4440, Loss function: 3.606, Average Loss: 3.971, avg. samples / sec: 2596.89
Iteration:   4460, Loss function: 3.795, Average Loss: 3.967, avg. samples / sec: 2586.43
Iteration:   4480, Loss function: 3.783, Average Loss: 3.965, avg. samples / sec: 2589.72
Iteration:   4500, Loss function: 4.125, Average Loss: 3.961, avg. samples / sec: 2594.38
:::MLL 1572950492.780 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1572950492.781 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   4520, Loss function: 3.948, Average Loss: 3.959, avg. samples / sec: 2587.06
Iteration:   4540, Loss function: 3.918, Average Loss: 3.956, avg. samples / sec: 2583.13
Iteration:   4560, Loss function: 3.734, Average Loss: 3.953, avg. samples / sec: 2598.92
Iteration:   4580, Loss function: 3.711, Average Loss: 3.949, avg. samples / sec: 2598.52
Iteration:   4600, Loss function: 3.919, Average Loss: 3.946, avg. samples / sec: 2602.45
Iteration:   4620, Loss function: 3.617, Average Loss: 3.943, avg. samples / sec: 2600.12
Iteration:   4640, Loss function: 3.781, Average Loss: 3.940, avg. samples / sec: 2596.97
:::MLL 1572950537.894 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1572950537.894 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   4660, Loss function: 3.750, Average Loss: 3.937, avg. samples / sec: 2581.59
Iteration:   4680, Loss function: 3.828, Average Loss: 3.934, avg. samples / sec: 2590.78
Iteration:   4700, Loss function: 3.778, Average Loss: 3.931, avg. samples / sec: 2597.07
Iteration:   4720, Loss function: 3.871, Average Loss: 3.929, avg. samples / sec: 2595.49
Iteration:   4740, Loss function: 3.774, Average Loss: 3.926, avg. samples / sec: 2598.60
Iteration:   4760, Loss function: 3.630, Average Loss: 3.924, avg. samples / sec: 2597.19
:::MLL 1572950583.052 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1572950583.053 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   4780, Loss function: 3.897, Average Loss: 3.921, avg. samples / sec: 2592.36
Iteration:   4800, Loss function: 3.563, Average Loss: 3.919, avg. samples / sec: 2595.26
Iteration:   4820, Loss function: 3.749, Average Loss: 3.916, avg. samples / sec: 2586.55
Iteration:   4840, Loss function: 3.920, Average Loss: 3.913, avg. samples / sec: 2596.00
Iteration:   4860, Loss function: 3.877, Average Loss: 3.910, avg. samples / sec: 2591.38
Iteration:   4880, Loss function: 3.969, Average Loss: 3.908, avg. samples / sec: 2601.22
:::MLL 1572950628.584 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1572950628.585 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   4900, Loss function: 3.701, Average Loss: 3.905, avg. samples / sec: 2591.77
Iteration:   4920, Loss function: 3.534, Average Loss: 3.902, avg. samples / sec: 2594.10
Iteration:   4940, Loss function: 3.530, Average Loss: 3.898, avg. samples / sec: 2595.00
Iteration:   4960, Loss function: 3.536, Average Loss: 3.894, avg. samples / sec: 2595.69
Iteration:   4980, Loss function: 3.768, Average Loss: 3.892, avg. samples / sec: 2588.92
Iteration:   5000, Loss function: 3.778, Average Loss: 3.891, avg. samples / sec: 2596.93
:::MLL 1572950673.739 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1572950673.739 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   5020, Loss function: 3.695, Average Loss: 3.889, avg. samples / sec: 2589.46
Iteration:   5040, Loss function: 3.703, Average Loss: 3.887, avg. samples / sec: 2592.74
Iteration:   5060, Loss function: 3.815, Average Loss: 3.885, avg. samples / sec: 2590.73
Iteration:   5080, Loss function: 3.779, Average Loss: 3.883, avg. samples / sec: 2591.87
Iteration:   5100, Loss function: 3.621, Average Loss: 3.881, avg. samples / sec: 2590.48
Iteration:   5120, Loss function: 3.694, Average Loss: 3.878, avg. samples / sec: 2602.09
:::MLL 1572950718.891 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1572950718.892 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   5140, Loss function: 3.453, Average Loss: 3.874, avg. samples / sec: 2597.63
Iteration:   5160, Loss function: 3.609, Average Loss: 3.871, avg. samples / sec: 2597.87
Iteration:   5180, Loss function: 3.588, Average Loss: 3.869, avg. samples / sec: 2592.39
Iteration:   5200, Loss function: 3.872, Average Loss: 3.866, avg. samples / sec: 2600.10
Iteration:   5220, Loss function: 3.681, Average Loss: 3.863, avg. samples / sec: 2594.91
Iteration:   5240, Loss function: 3.426, Average Loss: 3.861, avg. samples / sec: 2597.83
:::MLL 1572950763.991 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1572950763.992 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   5260, Loss function: 3.852, Average Loss: 3.858, avg. samples / sec: 2594.83
Iteration:   5280, Loss function: 4.045, Average Loss: 3.856, avg. samples / sec: 2594.00
Iteration:   5300, Loss function: 3.932, Average Loss: 3.854, avg. samples / sec: 2594.30
Iteration:   5320, Loss function: 3.817, Average Loss: 3.852, avg. samples / sec: 2592.83
lr decay step #1
:::MLL 1572950793.995 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 7.10 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.55s)
DONE (t=0.57s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.59s)
DONE (t=2.97s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.18878
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.34326
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.18609
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05513
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.19646
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.30712
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.19510
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.28414
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29924
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08905
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31877
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.47118
Current AP: 0.18878 AP goal: 0.23000
:::MLL 1572950804.699 eval_accuracy: {"value": 0.18877637447213158, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1572950804.780 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1572950804.817 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1572950804.817 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   5340, Loss function: 3.511, Average Loss: 3.848, avg. samples / sec: 1051.89
Iteration:   5360, Loss function: 3.314, Average Loss: 3.842, avg. samples / sec: 2621.10
:::MLL 1572950819.884 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1572950819.885 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   5380, Loss function: 3.443, Average Loss: 3.836, avg. samples / sec: 2611.10
Iteration:   5400, Loss function: 3.316, Average Loss: 3.829, avg. samples / sec: 2604.52
Iteration:   5420, Loss function: 3.347, Average Loss: 3.820, avg. samples / sec: 2602.81
Iteration:   5440, Loss function: 3.165, Average Loss: 3.811, avg. samples / sec: 2596.16
Iteration:   5460, Loss function: 3.590, Average Loss: 3.802, avg. samples / sec: 2594.78
Iteration:   5480, Loss function: 3.307, Average Loss: 3.794, avg. samples / sec: 2597.38
:::MLL 1572950864.962 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1572950864.963 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   5500, Loss function: 3.395, Average Loss: 3.786, avg. samples / sec: 2589.70
Iteration:   5520, Loss function: 3.424, Average Loss: 3.777, avg. samples / sec: 2595.43
Iteration:   5540, Loss function: 3.222, Average Loss: 3.768, avg. samples / sec: 2597.99
Iteration:   5560, Loss function: 3.354, Average Loss: 3.760, avg. samples / sec: 2596.22
Iteration:   5580, Loss function: 3.490, Average Loss: 3.753, avg. samples / sec: 2593.78
Iteration:   5600, Loss function: 3.344, Average Loss: 3.744, avg. samples / sec: 2596.80
:::MLL 1572950910.095 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1572950910.095 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   5620, Loss function: 3.328, Average Loss: 3.736, avg. samples / sec: 2592.47
Iteration:   5640, Loss function: 3.314, Average Loss: 3.728, avg. samples / sec: 2602.09
Iteration:   5660, Loss function: 3.639, Average Loss: 3.721, avg. samples / sec: 2592.98
Iteration:   5680, Loss function: 3.258, Average Loss: 3.714, avg. samples / sec: 2598.00
Iteration:   5700, Loss function: 3.243, Average Loss: 3.706, avg. samples / sec: 2597.62
Iteration:   5720, Loss function: 3.177, Average Loss: 3.698, avg. samples / sec: 2592.09
Iteration:   5740, Loss function: 3.519, Average Loss: 3.691, avg. samples / sec: 2594.55
:::MLL 1572950955.582 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1572950955.583 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   5760, Loss function: 3.290, Average Loss: 3.683, avg. samples / sec: 2578.20
Iteration:   5780, Loss function: 3.206, Average Loss: 3.676, avg. samples / sec: 2598.63
Iteration:   5800, Loss function: 3.307, Average Loss: 3.670, avg. samples / sec: 2589.08
Iteration:   5820, Loss function: 3.445, Average Loss: 3.663, avg. samples / sec: 2591.70
Iteration:   5840, Loss function: 3.476, Average Loss: 3.657, avg. samples / sec: 2597.72
Iteration:   5860, Loss function: 3.181, Average Loss: 3.650, avg. samples / sec: 2590.46
:::MLL 1572951000.788 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1572951000.788 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   5880, Loss function: 3.441, Average Loss: 3.642, avg. samples / sec: 2588.58
Iteration:   5900, Loss function: 3.210, Average Loss: 3.635, avg. samples / sec: 2597.99
Iteration:   5920, Loss function: 3.544, Average Loss: 3.628, avg. samples / sec: 2596.42
Iteration:   5940, Loss function: 3.518, Average Loss: 3.621, avg. samples / sec: 2592.20
Iteration:   5960, Loss function: 3.442, Average Loss: 3.614, avg. samples / sec: 2588.56
Iteration:   5980, Loss function: 3.121, Average Loss: 3.606, avg. samples / sec: 2593.92
:::MLL 1572951045.961 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1572951045.962 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   6000, Loss function: 3.448, Average Loss: 3.601, avg. samples / sec: 2585.67
:::MLL 1572951051.532 eval_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 7.15 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
DONE (t=0.59s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.09s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23186
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39582
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23896
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06199
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24270
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37747
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22306
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32418
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34093
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10419
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36921
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52985
Current AP: 0.23186 AP goal: 0.23000
:::MLL 1572951062.426 eval_accuracy: {"value": 0.23185763331268008, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 389}}
:::MLL 1572951062.428 eval_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 392}}
:::MLL 1572951062.463 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1572951063.150 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-2,24-26', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=3-5,27-29', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=6-8,30-32', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=9-11,33-35', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=12-14,36-38', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-17,39-41', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=18-20,42-44', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=21-23,45-47', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-11-05 10:51:10 AM
RESULT,SINGLE_STAGE_DETECTOR,,2295,nvidia,2019-11-05 10:12:55 AM
