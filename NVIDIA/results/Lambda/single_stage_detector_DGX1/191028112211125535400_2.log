Beginning trial 2 of 3
Gathering sys log on lambda-server
:::MLL 1572288372.757 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1572288372.759 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1572288372.760 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1572288372.761 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1572288372.762 submission_platform: {"value": "1xSYS-4029GP-TVRT", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1572288372.763 submission_entry: {"value": "{'hardware': 'SYS-4029GP-TVRT', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': ' ', 'os': 'Ubuntu 18.04.3 LTS / ', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-1.0.0', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '1', 'cpu': '2x Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz', 'num_cores': '40', 'num_vcpus': '80', 'accelerator': 'Tesla V100-SXM2-32GB', 'num_accelerators': '8', 'sys_mem_size': '1510 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '2x 3.5T', 'cpu_accel_interconnect': 'UPI', 'network_card': '', 'num_network_cards': '0', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1572288372.764 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1572288372.765 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
:::MLL 1572288376.486 cache_clear: {"value": true, "metadata": {"file": "<string>", "lineno": 1}}
Launching on node lambda-server
+ pids+=($!)
+ set +x
++ eval echo
+++ echo
+ docker exec -e DGXSYSTEM=DGX1 -e 'MULTI_NODE= --master_port=5203' -e SLURM_JOB_ID=191028112211125535400 -e SLURM_NTASKS_PER_NODE= cont_191028112211125535400 ./run_and_time.sh
Run vars: id 191028112211125535400 gpus 8 mparams  --master_port=5203
STARTING TIMING RUN AT 2019-10-28 06:46:17 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --master_port=5203 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 120 --eval-batch-size 160 --warmup 650 --lr 2.92e-3 --wd 1.6e-4 --use-nvjpeg --use-roi-decode
:::MLL 1572288381.722 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572288381.722 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572288381.722 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572288381.723 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
BN group: 1
:::MLL 1572288381.729 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572288381.729 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572288381.729 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1572288381.729 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
BN group: 1
1 Using seed = 992949709
3 Using seed = 992949711
7 Using seed = 992949715
2 Using seed = 992949710
6 Using seed = 992949714
4 Using seed = 992949712
0 Using seed = 992949708
5 Using seed = 992949713
:::MLL 1572288391.482 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
:::MLL 1572288392.141 model_bn_span: {"value": 120, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1572288392.141 global_batch_size: {"value": 960, "metadata": {"file": "train.py", "lineno": 481}}
:::MLL 1572288392.147 opt_base_learning_rate: {"value": 0.08750000000000001, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1572288392.147 opt_weight_decay: {"value": 0.00016, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1572288392.147 opt_learning_rate_warmup_steps: {"value": 650, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1572288392.148 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
epoch nbatch loss
:::MLL 1572288398.567 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1572288398.568 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.47s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.52s)
creating index...
Done (t=0.53s)
creating index...
Done (t=0.54s)
creating index...
time_check a: 1572288400.451278925
time_check b: 1572288404.212962151
:::MLL 1572288404.843 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1572288404.844 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 23.292, Average Loss: 0.023, avg. samples / sec: 73.04
Iteration:     20, Loss function: 20.717, Average Loss: 0.448, avg. samples / sec: 3879.62
Iteration:     40, Loss function: 17.719, Average Loss: 0.835, avg. samples / sec: 4225.87
Iteration:     60, Loss function: 13.694, Average Loss: 1.092, avg. samples / sec: 4263.23
Iteration:     80, Loss function: 11.703, Average Loss: 1.301, avg. samples / sec: 4319.54
Iteration:    100, Loss function: 9.920, Average Loss: 1.476, avg. samples / sec: 4306.52
Iteration:    120, Loss function: 9.134, Average Loss: 1.632, avg. samples / sec: 4299.14
:::MLL 1572288433.829 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1572288433.829 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 9.145, Average Loss: 1.777, avg. samples / sec: 4303.56
Iteration:    160, Loss function: 8.699, Average Loss: 1.920, avg. samples / sec: 4340.06
Iteration:    180, Loss function: 8.350, Average Loss: 2.049, avg. samples / sec: 4331.35
Iteration:    200, Loss function: 8.106, Average Loss: 2.173, avg. samples / sec: 4348.48
Iteration:    220, Loss function: 7.725, Average Loss: 2.292, avg. samples / sec: 4334.62
Iteration:    240, Loss function: 7.827, Average Loss: 2.403, avg. samples / sec: 4320.24
:::MLL 1572288460.869 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1572288460.870 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    260, Loss function: 7.854, Average Loss: 2.513, avg. samples / sec: 4320.58
Iteration:    280, Loss function: 7.491, Average Loss: 2.615, avg. samples / sec: 4329.28
Iteration:    300, Loss function: 7.536, Average Loss: 2.713, avg. samples / sec: 4335.87
Iteration:    320, Loss function: 7.266, Average Loss: 2.806, avg. samples / sec: 4334.36
Iteration:    340, Loss function: 7.441, Average Loss: 2.894, avg. samples / sec: 4325.61
Iteration:    360, Loss function: 7.209, Average Loss: 2.984, avg. samples / sec: 4321.87
:::MLL 1572288487.936 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1572288487.936 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    380, Loss function: 6.891, Average Loss: 3.065, avg. samples / sec: 4306.89
Iteration:    400, Loss function: 7.063, Average Loss: 3.140, avg. samples / sec: 4319.97
Iteration:    420, Loss function: 6.896, Average Loss: 3.218, avg. samples / sec: 4318.91
Iteration:    440, Loss function: 6.567, Average Loss: 3.289, avg. samples / sec: 4321.95
Iteration:    460, Loss function: 6.316, Average Loss: 3.355, avg. samples / sec: 4321.02
Iteration:    480, Loss function: 6.734, Average Loss: 3.420, avg. samples / sec: 4296.48
:::MLL 1572288515.077 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1572288515.078 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 6.045, Average Loss: 3.481, avg. samples / sec: 4310.76
Iteration:    520, Loss function: 6.169, Average Loss: 3.537, avg. samples / sec: 4320.18
Iteration:    540, Loss function: 6.031, Average Loss: 3.591, avg. samples / sec: 4332.41
Iteration:    560, Loss function: 6.107, Average Loss: 3.645, avg. samples / sec: 4318.37
Iteration:    580, Loss function: 6.005, Average Loss: 3.694, avg. samples / sec: 4310.37
Iteration:    600, Loss function: 5.804, Average Loss: 3.741, avg. samples / sec: 4326.99
:::MLL 1572288542.194 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1572288542.194 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    620, Loss function: 5.827, Average Loss: 3.787, avg. samples / sec: 4308.47
Iteration:    640, Loss function: 5.893, Average Loss: 3.831, avg. samples / sec: 4314.23
Iteration:    660, Loss function: 5.861, Average Loss: 3.872, avg. samples / sec: 4323.30
Iteration:    680, Loss function: 5.638, Average Loss: 3.910, avg. samples / sec: 4323.65
Iteration:    700, Loss function: 5.738, Average Loss: 3.945, avg. samples / sec: 4325.08
Iteration:    720, Loss function: 5.829, Average Loss: 3.982, avg. samples / sec: 4330.61
:::MLL 1572288569.307 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1572288569.307 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    740, Loss function: 5.658, Average Loss: 4.016, avg. samples / sec: 4308.34
Iteration:    760, Loss function: 5.507, Average Loss: 4.045, avg. samples / sec: 4317.88
Iteration:    780, Loss function: 5.551, Average Loss: 4.073, avg. samples / sec: 4332.73
Iteration:    800, Loss function: 5.290, Average Loss: 4.098, avg. samples / sec: 4320.19
Iteration:    820, Loss function: 5.544, Average Loss: 4.126, avg. samples / sec: 4320.60
Iteration:    840, Loss function: 5.577, Average Loss: 4.151, avg. samples / sec: 4320.86
:::MLL 1572288596.632 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1572288596.632 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    860, Loss function: 5.282, Average Loss: 4.173, avg. samples / sec: 4306.09
Iteration:    880, Loss function: 5.276, Average Loss: 4.195, avg. samples / sec: 4324.55
Iteration:    900, Loss function: 5.411, Average Loss: 4.216, avg. samples / sec: 4318.47
Iteration:    920, Loss function: 5.275, Average Loss: 4.236, avg. samples / sec: 4303.26
Iteration:    940, Loss function: 5.123, Average Loss: 4.255, avg. samples / sec: 4314.48
Iteration:    960, Loss function: 4.868, Average Loss: 4.272, avg. samples / sec: 4319.02
:::MLL 1572288623.781 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1572288623.782 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 4.821, Average Loss: 4.288, avg. samples / sec: 4308.84
Iteration:   1000, Loss function: 5.228, Average Loss: 4.303, avg. samples / sec: 4329.22
Iteration:   1020, Loss function: 4.793, Average Loss: 4.316, avg. samples / sec: 4315.95
Iteration:   1040, Loss function: 5.063, Average Loss: 4.331, avg. samples / sec: 4319.60
Iteration:   1060, Loss function: 4.919, Average Loss: 4.343, avg. samples / sec: 4318.91
Iteration:   1080, Loss function: 4.791, Average Loss: 4.356, avg. samples / sec: 4317.47
:::MLL 1572288650.903 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1572288650.903 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:   1100, Loss function: 4.874, Average Loss: 4.369, avg. samples / sec: 4315.83
Iteration:   1120, Loss function: 5.195, Average Loss: 4.378, avg. samples / sec: 4315.23
Iteration:   1140, Loss function: 5.072, Average Loss: 4.387, avg. samples / sec: 4320.37
Iteration:   1160, Loss function: 4.966, Average Loss: 4.398, avg. samples / sec: 4314.26
Iteration:   1180, Loss function: 5.014, Average Loss: 4.406, avg. samples / sec: 4314.32
Iteration:   1200, Loss function: 4.770, Average Loss: 4.414, avg. samples / sec: 4318.40
Iteration:   1220, Loss function: 5.033, Average Loss: 4.423, avg. samples / sec: 4316.91
:::MLL 1572288678.043 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1572288678.043 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:   1240, Loss function: 4.669, Average Loss: 4.430, avg. samples / sec: 4315.09
Iteration:   1260, Loss function: 4.728, Average Loss: 4.436, avg. samples / sec: 4315.97
Iteration:   1280, Loss function: 4.795, Average Loss: 4.440, avg. samples / sec: 4321.54
Iteration:   1300, Loss function: 4.523, Average Loss: 4.446, avg. samples / sec: 4290.45
Iteration:   1320, Loss function: 4.874, Average Loss: 4.453, avg. samples / sec: 4329.01
Iteration:   1340, Loss function: 4.867, Average Loss: 4.459, avg. samples / sec: 4324.33
:::MLL 1572288705.172 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1572288705.173 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:   1360, Loss function: 4.885, Average Loss: 4.462, avg. samples / sec: 4314.24
Iteration:   1380, Loss function: 4.472, Average Loss: 4.466, avg. samples / sec: 4324.13
Iteration:   1400, Loss function: 4.307, Average Loss: 4.470, avg. samples / sec: 4327.96
Iteration:   1420, Loss function: 4.685, Average Loss: 4.473, avg. samples / sec: 4325.96
Iteration:   1440, Loss function: 4.580, Average Loss: 4.478, avg. samples / sec: 4306.57
Iteration:   1460, Loss function: 4.803, Average Loss: 4.481, avg. samples / sec: 4316.04
:::MLL 1572288732.293 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1572288732.294 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.454, Average Loss: 4.482, avg. samples / sec: 4307.57
Iteration:   1500, Loss function: 4.516, Average Loss: 4.483, avg. samples / sec: 4297.16
Iteration:   1520, Loss function: 4.594, Average Loss: 4.484, avg. samples / sec: 4308.75
Iteration:   1540, Loss function: 4.351, Average Loss: 4.483, avg. samples / sec: 4314.10
Iteration:   1560, Loss function: 4.530, Average Loss: 4.484, avg. samples / sec: 4323.07
Iteration:   1580, Loss function: 4.474, Average Loss: 4.486, avg. samples / sec: 4321.63
:::MLL 1572288759.459 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1572288759.461 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:   1600, Loss function: 4.567, Average Loss: 4.485, avg. samples / sec: 4318.09
Iteration:   1620, Loss function: 4.422, Average Loss: 4.486, avg. samples / sec: 4305.81
Iteration:   1640, Loss function: 4.497, Average Loss: 4.485, avg. samples / sec: 4323.05
Iteration:   1660, Loss function: 4.320, Average Loss: 4.485, avg. samples / sec: 4317.35
Iteration:   1680, Loss function: 4.274, Average Loss: 4.484, avg. samples / sec: 4320.85
Iteration:   1700, Loss function: 4.420, Average Loss: 4.484, avg. samples / sec: 4325.51
:::MLL 1572288786.795 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1572288786.796 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:   1720, Loss function: 4.476, Average Loss: 4.484, avg. samples / sec: 4317.63
Iteration:   1740, Loss function: 4.579, Average Loss: 4.482, avg. samples / sec: 4309.90
Iteration:   1760, Loss function: 4.523, Average Loss: 4.482, avg. samples / sec: 4326.19
Iteration:   1780, Loss function: 4.388, Average Loss: 4.481, avg. samples / sec: 4304.84
Iteration:   1800, Loss function: 4.484, Average Loss: 4.478, avg. samples / sec: 4316.47
Iteration:   1820, Loss function: 4.471, Average Loss: 4.478, avg. samples / sec: 4317.31
:::MLL 1572288813.946 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1572288813.947 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:   1840, Loss function: 4.508, Average Loss: 4.477, avg. samples / sec: 4306.92
Iteration:   1860, Loss function: 4.226, Average Loss: 4.474, avg. samples / sec: 4319.30
Iteration:   1880, Loss function: 4.660, Average Loss: 4.472, avg. samples / sec: 4311.66
Iteration:   1900, Loss function: 4.543, Average Loss: 4.471, avg. samples / sec: 4323.91
Iteration:   1920, Loss function: 4.234, Average Loss: 4.468, avg. samples / sec: 4323.63
Iteration:   1940, Loss function: 4.503, Average Loss: 4.466, avg. samples / sec: 4326.31
:::MLL 1572288841.061 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1572288841.061 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 4.357, Average Loss: 4.464, avg. samples / sec: 4311.07
Iteration:   1980, Loss function: 4.160, Average Loss: 4.461, avg. samples / sec: 4323.78
Iteration:   2000, Loss function: 4.534, Average Loss: 4.456, avg. samples / sec: 4319.20
Iteration:   2020, Loss function: 4.275, Average Loss: 4.454, avg. samples / sec: 4322.60
Iteration:   2040, Loss function: 4.029, Average Loss: 4.452, avg. samples / sec: 4320.63
Iteration:   2060, Loss function: 4.360, Average Loss: 4.449, avg. samples / sec: 4326.68
:::MLL 1572288868.171 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1572288868.171 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   2080, Loss function: 4.300, Average Loss: 4.446, avg. samples / sec: 4302.40
Iteration:   2100, Loss function: 4.395, Average Loss: 4.444, avg. samples / sec: 4308.59
Iteration:   2120, Loss function: 4.449, Average Loss: 4.440, avg. samples / sec: 4310.92
Iteration:   2140, Loss function: 4.207, Average Loss: 4.437, avg. samples / sec: 4324.35
Iteration:   2160, Loss function: 4.321, Average Loss: 4.434, avg. samples / sec: 4320.57
Iteration:   2180, Loss function: 4.131, Average Loss: 4.430, avg. samples / sec: 4326.41
:::MLL 1572288895.299 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1572288895.299 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   2200, Loss function: 4.175, Average Loss: 4.426, avg. samples / sec: 4311.82
Iteration:   2220, Loss function: 4.134, Average Loss: 4.421, avg. samples / sec: 4312.59
Iteration:   2240, Loss function: 4.165, Average Loss: 4.416, avg. samples / sec: 4297.20
Iteration:   2260, Loss function: 4.646, Average Loss: 4.413, avg. samples / sec: 4326.56
Iteration:   2280, Loss function: 4.295, Average Loss: 4.409, avg. samples / sec: 4316.61
Iteration:   2300, Loss function: 4.176, Average Loss: 4.407, avg. samples / sec: 4301.23
Iteration:   2320, Loss function: 4.561, Average Loss: 4.404, avg. samples / sec: 4316.75
:::MLL 1572288922.472 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1572288922.473 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   2340, Loss function: 4.028, Average Loss: 4.400, avg. samples / sec: 4326.77
Iteration:   2360, Loss function: 3.915, Average Loss: 4.395, avg. samples / sec: 4303.24
Iteration:   2380, Loss function: 4.128, Average Loss: 4.391, avg. samples / sec: 4317.22
Iteration:   2400, Loss function: 4.355, Average Loss: 4.387, avg. samples / sec: 4314.97
Iteration:   2420, Loss function: 4.047, Average Loss: 4.383, avg. samples / sec: 4313.85
Iteration:   2440, Loss function: 4.100, Average Loss: 4.379, avg. samples / sec: 4299.82
:::MLL 1572288949.847 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1572288949.847 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 4.391, Average Loss: 4.375, avg. samples / sec: 4313.85
Iteration:   2480, Loss function: 4.105, Average Loss: 4.371, avg. samples / sec: 4306.56
Iteration:   2500, Loss function: 4.498, Average Loss: 4.367, avg. samples / sec: 4311.56
Iteration:   2520, Loss function: 3.996, Average Loss: 4.362, avg. samples / sec: 4318.37
Iteration:   2540, Loss function: 4.206, Average Loss: 4.359, avg. samples / sec: 4325.52
Iteration:   2560, Loss function: 3.853, Average Loss: 4.355, avg. samples / sec: 4308.63
:::MLL 1572288977.002 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1572288977.003 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   2580, Loss function: 4.082, Average Loss: 4.351, avg. samples / sec: 4304.43
Iteration:   2600, Loss function: 4.232, Average Loss: 4.346, avg. samples / sec: 4322.87
Iteration:   2620, Loss function: 3.893, Average Loss: 4.341, avg. samples / sec: 4304.01
Iteration:   2640, Loss function: 4.078, Average Loss: 4.336, avg. samples / sec: 4326.14
Iteration:   2660, Loss function: 3.976, Average Loss: 4.330, avg. samples / sec: 4320.20
Iteration:   2680, Loss function: 3.936, Average Loss: 4.327, avg. samples / sec: 4303.20
:::MLL 1572289004.163 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1572289004.164 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   2700, Loss function: 4.251, Average Loss: 4.323, avg. samples / sec: 4298.22
Iteration:   2720, Loss function: 3.948, Average Loss: 4.318, avg. samples / sec: 4305.22
Iteration:   2740, Loss function: 3.955, Average Loss: 4.314, avg. samples / sec: 4316.35
Iteration:   2760, Loss function: 4.250, Average Loss: 4.309, avg. samples / sec: 4319.75
Iteration:   2780, Loss function: 4.142, Average Loss: 4.306, avg. samples / sec: 4324.32
Iteration:   2800, Loss function: 3.994, Average Loss: 4.302, avg. samples / sec: 4306.53
:::MLL 1572289031.315 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1572289031.315 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   2820, Loss function: 4.028, Average Loss: 4.298, avg. samples / sec: 4312.12
Iteration:   2840, Loss function: 4.027, Average Loss: 4.293, avg. samples / sec: 4312.33
Iteration:   2860, Loss function: 3.765, Average Loss: 4.288, avg. samples / sec: 4315.69
Iteration:   2880, Loss function: 4.037, Average Loss: 4.283, avg. samples / sec: 4318.22
Iteration:   2900, Loss function: 4.244, Average Loss: 4.280, avg. samples / sec: 4325.83
Iteration:   2920, Loss function: 4.240, Average Loss: 4.278, avg. samples / sec: 4321.83
:::MLL 1572289058.442 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1572289058.442 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.908, Average Loss: 4.273, avg. samples / sec: 4302.08
Iteration:   2960, Loss function: 4.039, Average Loss: 4.268, avg. samples / sec: 4326.29
Iteration:   2980, Loss function: 3.972, Average Loss: 4.263, avg. samples / sec: 4321.41
Iteration:   3000, Loss function: 4.262, Average Loss: 4.258, avg. samples / sec: 4314.03
Iteration:   3020, Loss function: 4.333, Average Loss: 4.254, avg. samples / sec: 4316.57
Iteration:   3040, Loss function: 3.845, Average Loss: 4.251, avg. samples / sec: 4313.17
:::MLL 1572289085.583 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1572289085.584 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   3060, Loss function: 3.897, Average Loss: 4.247, avg. samples / sec: 4314.36
Iteration:   3080, Loss function: 3.946, Average Loss: 4.241, avg. samples / sec: 4319.81
Iteration:   3100, Loss function: 4.051, Average Loss: 4.236, avg. samples / sec: 4311.33
Iteration:   3120, Loss function: 3.935, Average Loss: 4.232, avg. samples / sec: 4322.29
Iteration:   3140, Loss function: 3.952, Average Loss: 4.228, avg. samples / sec: 4329.91
Iteration:   3160, Loss function: 4.025, Average Loss: 4.224, avg. samples / sec: 4321.71
:::MLL 1572289112.693 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1572289112.693 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   3180, Loss function: 4.317, Average Loss: 4.220, avg. samples / sec: 4314.97
Iteration:   3200, Loss function: 4.151, Average Loss: 4.216, avg. samples / sec: 4320.34
Iteration:   3220, Loss function: 3.902, Average Loss: 4.210, avg. samples / sec: 4324.85
Iteration:   3240, Loss function: 4.013, Average Loss: 4.206, avg. samples / sec: 4322.92
Iteration:   3260, Loss function: 3.944, Average Loss: 4.200, avg. samples / sec: 4324.31
Iteration:   3280, Loss function: 3.873, Average Loss: 4.195, avg. samples / sec: 4300.95
:::MLL 1572289140.056 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1572289140.056 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 3.960, Average Loss: 4.193, avg. samples / sec: 4300.60
Iteration:   3320, Loss function: 4.013, Average Loss: 4.188, avg. samples / sec: 4327.51
Iteration:   3340, Loss function: 4.197, Average Loss: 4.184, avg. samples / sec: 4316.69
Iteration:   3360, Loss function: 4.053, Average Loss: 4.181, avg. samples / sec: 4325.01
Iteration:   3380, Loss function: 3.947, Average Loss: 4.176, avg. samples / sec: 4319.08
Iteration:   3400, Loss function: 3.776, Average Loss: 4.171, avg. samples / sec: 4322.92
Iteration:   3420, Loss function: 3.610, Average Loss: 4.167, avg. samples / sec: 4321.43
:::MLL 1572289167.158 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1572289167.159 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.657, Average Loss: 4.161, avg. samples / sec: 4303.28
Iteration:   3460, Loss function: 4.116, Average Loss: 4.158, avg. samples / sec: 4326.48
Iteration:   3480, Loss function: 4.033, Average Loss: 4.154, avg. samples / sec: 4314.08
Iteration:   3500, Loss function: 3.802, Average Loss: 4.149, avg. samples / sec: 4328.46
Iteration:   3520, Loss function: 3.700, Average Loss: 4.146, avg. samples / sec: 4328.15
Iteration:   3540, Loss function: 4.246, Average Loss: 4.141, avg. samples / sec: 4303.71
:::MLL 1572289194.281 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1572289194.282 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 4.102, Average Loss: 4.137, avg. samples / sec: 4309.18
Iteration:   3580, Loss function: 3.932, Average Loss: 4.132, avg. samples / sec: 4324.83
Iteration:   3600, Loss function: 3.978, Average Loss: 4.130, avg. samples / sec: 4317.61
Iteration:   3620, Loss function: 3.978, Average Loss: 4.127, avg. samples / sec: 4318.58
Iteration:   3640, Loss function: 4.108, Average Loss: 4.125, avg. samples / sec: 4312.13
Iteration:   3660, Loss function: 3.455, Average Loss: 4.120, avg. samples / sec: 4325.37
:::MLL 1572289221.406 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1572289221.407 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   3680, Loss function: 4.024, Average Loss: 4.116, avg. samples / sec: 4330.67
Iteration:   3700, Loss function: 4.091, Average Loss: 4.112, avg. samples / sec: 4316.77
Iteration:   3720, Loss function: 3.980, Average Loss: 4.107, avg. samples / sec: 4333.83
Iteration:   3740, Loss function: 3.915, Average Loss: 4.104, avg. samples / sec: 4308.03
Iteration:   3760, Loss function: 3.980, Average Loss: 4.100, avg. samples / sec: 4322.84
Iteration:   3780, Loss function: 3.640, Average Loss: 4.096, avg. samples / sec: 4319.51
:::MLL 1572289248.506 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1572289248.506 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   3800, Loss function: 3.921, Average Loss: 4.091, avg. samples / sec: 4323.79
Iteration:   3820, Loss function: 4.065, Average Loss: 4.088, avg. samples / sec: 4324.53
Iteration:   3840, Loss function: 3.993, Average Loss: 4.086, avg. samples / sec: 4303.73
Iteration:   3860, Loss function: 3.952, Average Loss: 4.083, avg. samples / sec: 4321.82
Iteration:   3880, Loss function: 3.917, Average Loss: 4.080, avg. samples / sec: 4304.28
Iteration:   3900, Loss function: 4.039, Average Loss: 4.078, avg. samples / sec: 4310.12
:::MLL 1572289275.656 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1572289275.657 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   3920, Loss function: 3.862, Average Loss: 4.075, avg. samples / sec: 4310.80
Iteration:   3940, Loss function: 3.883, Average Loss: 4.071, avg. samples / sec: 4313.36
Iteration:   3960, Loss function: 3.933, Average Loss: 4.067, avg. samples / sec: 4311.53
Iteration:   3980, Loss function: 3.946, Average Loss: 4.065, avg. samples / sec: 4325.94
Iteration:   4000, Loss function: 4.084, Average Loss: 4.060, avg. samples / sec: 4304.48
:::MLL 1572289296.134 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 7.11 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.42s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
DONE (t=0.43s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.03s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17729
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32988
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17288
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04449
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.18280
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.28987
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18916
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27950
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29521
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08327
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.45955
Current AP: 0.17729 AP goal: 0.23000
:::MLL 1572289306.771 eval_accuracy: {"value": 0.17729329141566888, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1572289306.799 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1572289306.826 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1572289306.827 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
Iteration:   4020, Loss function: 3.546, Average Loss: 4.056, avg. samples / sec: 1242.97
:::MLL 1572289314.026 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1572289314.026 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   4040, Loss function: 4.185, Average Loss: 4.053, avg. samples / sec: 4303.71
Iteration:   4060, Loss function: 4.058, Average Loss: 4.050, avg. samples / sec: 4346.49
Iteration:   4080, Loss function: 3.566, Average Loss: 4.046, avg. samples / sec: 4330.28
Iteration:   4100, Loss function: 3.839, Average Loss: 4.042, avg. samples / sec: 4328.94
Iteration:   4120, Loss function: 3.763, Average Loss: 4.038, avg. samples / sec: 4321.12
Iteration:   4140, Loss function: 3.692, Average Loss: 4.036, avg. samples / sec: 4311.30
:::MLL 1572289341.125 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1572289341.126 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   4160, Loss function: 3.550, Average Loss: 4.032, avg. samples / sec: 4291.64
Iteration:   4180, Loss function: 3.887, Average Loss: 4.028, avg. samples / sec: 4303.79
Iteration:   4200, Loss function: 3.803, Average Loss: 4.025, avg. samples / sec: 4314.51
Iteration:   4220, Loss function: 3.752, Average Loss: 4.021, avg. samples / sec: 4317.23
Iteration:   4240, Loss function: 3.644, Average Loss: 4.017, avg. samples / sec: 4310.17
Iteration:   4260, Loss function: 3.920, Average Loss: 4.015, avg. samples / sec: 4316.13
:::MLL 1572289368.296 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1572289368.297 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   4280, Loss function: 3.952, Average Loss: 4.012, avg. samples / sec: 4303.63
Iteration:   4300, Loss function: 3.949, Average Loss: 4.009, avg. samples / sec: 4316.55
Iteration:   4320, Loss function: 3.843, Average Loss: 4.005, avg. samples / sec: 4320.96
Iteration:   4340, Loss function: 3.906, Average Loss: 4.002, avg. samples / sec: 4309.99
Iteration:   4360, Loss function: 3.715, Average Loss: 3.999, avg. samples / sec: 4326.70
Iteration:   4380, Loss function: 3.878, Average Loss: 3.996, avg. samples / sec: 4308.85
:::MLL 1572289395.446 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1572289395.446 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   4400, Loss function: 3.678, Average Loss: 3.993, avg. samples / sec: 4309.13
Iteration:   4420, Loss function: 3.877, Average Loss: 3.990, avg. samples / sec: 4316.26
Iteration:   4440, Loss function: 3.685, Average Loss: 3.987, avg. samples / sec: 4303.16
Iteration:   4460, Loss function: 3.946, Average Loss: 3.984, avg. samples / sec: 4296.59
Iteration:   4480, Loss function: 3.782, Average Loss: 3.981, avg. samples / sec: 4300.95
Iteration:   4500, Loss function: 4.041, Average Loss: 3.978, avg. samples / sec: 4303.49
:::MLL 1572289422.659 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1572289422.659 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   4520, Loss function: 4.214, Average Loss: 3.975, avg. samples / sec: 4298.41
Iteration:   4540, Loss function: 3.884, Average Loss: 3.971, avg. samples / sec: 4311.98
Iteration:   4560, Loss function: 3.837, Average Loss: 3.968, avg. samples / sec: 4318.15
Iteration:   4580, Loss function: 3.939, Average Loss: 3.964, avg. samples / sec: 4317.23
Iteration:   4600, Loss function: 4.178, Average Loss: 3.962, avg. samples / sec: 4313.33
Iteration:   4620, Loss function: 3.682, Average Loss: 3.959, avg. samples / sec: 4316.08
Iteration:   4640, Loss function: 3.789, Average Loss: 3.957, avg. samples / sec: 4306.86
:::MLL 1572289449.814 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1572289449.815 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   4660, Loss function: 3.756, Average Loss: 3.954, avg. samples / sec: 4300.14
Iteration:   4680, Loss function: 3.937, Average Loss: 3.951, avg. samples / sec: 4296.61
Iteration:   4700, Loss function: 3.659, Average Loss: 3.947, avg. samples / sec: 4305.21
Iteration:   4720, Loss function: 3.724, Average Loss: 3.944, avg. samples / sec: 4296.88
Iteration:   4740, Loss function: 3.809, Average Loss: 3.942, avg. samples / sec: 4295.40
Iteration:   4760, Loss function: 3.707, Average Loss: 3.940, avg. samples / sec: 4306.13
:::MLL 1572289477.048 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1572289477.049 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   4780, Loss function: 4.144, Average Loss: 3.937, avg. samples / sec: 4302.52
Iteration:   4800, Loss function: 3.554, Average Loss: 3.934, avg. samples / sec: 4300.57
Iteration:   4820, Loss function: 3.721, Average Loss: 3.930, avg. samples / sec: 4312.00
Iteration:   4840, Loss function: 3.890, Average Loss: 3.927, avg. samples / sec: 4314.17
Iteration:   4860, Loss function: 3.906, Average Loss: 3.924, avg. samples / sec: 4295.31
Iteration:   4880, Loss function: 3.970, Average Loss: 3.922, avg. samples / sec: 4313.67
:::MLL 1572289504.473 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1572289504.474 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   4900, Loss function: 3.704, Average Loss: 3.918, avg. samples / sec: 4312.67
Iteration:   4920, Loss function: 3.589, Average Loss: 3.915, avg. samples / sec: 4312.56
Iteration:   4940, Loss function: 3.556, Average Loss: 3.911, avg. samples / sec: 4319.24
Iteration:   4960, Loss function: 3.633, Average Loss: 3.908, avg. samples / sec: 4322.25
Iteration:   4980, Loss function: 3.658, Average Loss: 3.906, avg. samples / sec: 4293.03
Iteration:   5000, Loss function: 3.601, Average Loss: 3.904, avg. samples / sec: 4305.05
:::MLL 1572289531.639 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1572289531.640 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   5020, Loss function: 3.496, Average Loss: 3.900, avg. samples / sec: 4306.16
Iteration:   5040, Loss function: 3.680, Average Loss: 3.898, avg. samples / sec: 4298.12
Iteration:   5060, Loss function: 3.807, Average Loss: 3.896, avg. samples / sec: 4309.82
Iteration:   5080, Loss function: 3.701, Average Loss: 3.894, avg. samples / sec: 4295.99
Iteration:   5100, Loss function: 3.826, Average Loss: 3.892, avg. samples / sec: 4309.36
Iteration:   5120, Loss function: 3.760, Average Loss: 3.889, avg. samples / sec: 4313.48
:::MLL 1572289558.834 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1572289558.835 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   5140, Loss function: 3.440, Average Loss: 3.886, avg. samples / sec: 4316.39
Iteration:   5160, Loss function: 3.654, Average Loss: 3.883, avg. samples / sec: 4311.56
Iteration:   5180, Loss function: 3.420, Average Loss: 3.880, avg. samples / sec: 4291.06
Iteration:   5200, Loss function: 3.932, Average Loss: 3.878, avg. samples / sec: 4298.11
Iteration:   5220, Loss function: 3.748, Average Loss: 3.874, avg. samples / sec: 4323.14
Iteration:   5240, Loss function: 3.580, Average Loss: 3.873, avg. samples / sec: 4315.82
:::MLL 1572289586.030 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1572289586.030 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   5260, Loss function: 3.722, Average Loss: 3.870, avg. samples / sec: 4298.25
Iteration:   5280, Loss function: 3.766, Average Loss: 3.867, avg. samples / sec: 4314.03
Iteration:   5300, Loss function: 4.066, Average Loss: 3.865, avg. samples / sec: 4316.22
Iteration:   5320, Loss function: 3.720, Average Loss: 3.862, avg. samples / sec: 4309.49
lr decay step #1
:::MLL 1572289604.073 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 6.36 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.60s)
DONE (t=0.61s)
DONE (t=0.61s)
DONE (t=0.61s)
DONE (t=0.61s)
DONE (t=0.61s)
DONE (t=0.61s)
DONE (t=0.61s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.25s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.18451
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33474
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.18685
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.19109
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.30304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.18995
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.27817
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.08386
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30853
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.47167
Current AP: 0.18451 AP goal: 0.23000
:::MLL 1572289614.353 eval_accuracy: {"value": 0.1845094874164871, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1572289614.358 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1572289614.386 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1572289614.386 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   5340, Loss function: 3.704, Average Loss: 3.859, avg. samples / sec: 1298.35
Iteration:   5360, Loss function: 3.377, Average Loss: 3.854, avg. samples / sec: 4334.06
:::MLL 1572289623.486 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1572289623.486 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   5380, Loss function: 3.320, Average Loss: 3.848, avg. samples / sec: 4325.18
Iteration:   5400, Loss function: 3.435, Average Loss: 3.841, avg. samples / sec: 4325.05
Iteration:   5420, Loss function: 3.171, Average Loss: 3.832, avg. samples / sec: 4309.34
Iteration:   5440, Loss function: 3.359, Average Loss: 3.823, avg. samples / sec: 4295.41
Iteration:   5460, Loss function: 3.834, Average Loss: 3.814, avg. samples / sec: 4321.09
Iteration:   5480, Loss function: 3.332, Average Loss: 3.805, avg. samples / sec: 4330.66
:::MLL 1572289650.631 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1572289650.631 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   5500, Loss function: 3.311, Average Loss: 3.797, avg. samples / sec: 4309.75
Iteration:   5520, Loss function: 3.335, Average Loss: 3.789, avg. samples / sec: 4325.41
Iteration:   5540, Loss function: 3.317, Average Loss: 3.780, avg. samples / sec: 4323.30
Iteration:   5560, Loss function: 3.265, Average Loss: 3.771, avg. samples / sec: 4321.18
Iteration:   5580, Loss function: 3.518, Average Loss: 3.764, avg. samples / sec: 4333.52
Iteration:   5600, Loss function: 3.309, Average Loss: 3.756, avg. samples / sec: 4321.82
:::MLL 1572289677.743 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1572289677.744 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   5620, Loss function: 3.268, Average Loss: 3.748, avg. samples / sec: 4291.13
Iteration:   5640, Loss function: 3.285, Average Loss: 3.740, avg. samples / sec: 4310.38
Iteration:   5660, Loss function: 3.496, Average Loss: 3.733, avg. samples / sec: 4311.08
Iteration:   5680, Loss function: 3.287, Average Loss: 3.725, avg. samples / sec: 4311.67
Iteration:   5700, Loss function: 3.062, Average Loss: 3.718, avg. samples / sec: 4324.97
Iteration:   5720, Loss function: 3.573, Average Loss: 3.710, avg. samples / sec: 4309.76
Iteration:   5740, Loss function: 3.501, Average Loss: 3.704, avg. samples / sec: 4309.31
:::MLL 1572289705.127 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1572289705.128 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   5760, Loss function: 3.344, Average Loss: 3.696, avg. samples / sec: 4304.92
Iteration:   5780, Loss function: 3.320, Average Loss: 3.690, avg. samples / sec: 4320.96
Iteration:   5800, Loss function: 3.535, Average Loss: 3.683, avg. samples / sec: 4322.14
Iteration:   5820, Loss function: 3.213, Average Loss: 3.676, avg. samples / sec: 4317.24
Iteration:   5840, Loss function: 3.499, Average Loss: 3.669, avg. samples / sec: 4322.02
Iteration:   5860, Loss function: 3.346, Average Loss: 3.663, avg. samples / sec: 4318.13
:::MLL 1572289732.252 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1572289732.253 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   5880, Loss function: 3.473, Average Loss: 3.655, avg. samples / sec: 4312.35
Iteration:   5900, Loss function: 3.216, Average Loss: 3.649, avg. samples / sec: 4303.52
Iteration:   5920, Loss function: 3.468, Average Loss: 3.641, avg. samples / sec: 4291.56
Iteration:   5940, Loss function: 3.557, Average Loss: 3.634, avg. samples / sec: 4316.44
Iteration:   5960, Loss function: 3.502, Average Loss: 3.628, avg. samples / sec: 4300.37
Iteration:   5980, Loss function: 2.927, Average Loss: 3.619, avg. samples / sec: 4323.50
:::MLL 1572289759.442 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1572289759.443 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   6000, Loss function: 3.368, Average Loss: 3.614, avg. samples / sec: 4314.98
:::MLL 1572289762.780 eval_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 276}}
Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 0/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 1/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 2/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Parsing batch: 3/4Predicting Ended, total time: 6.28 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.53s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
DONE (t=0.54s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.80s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23208
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39433
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23707
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05829
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37757
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22245
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32395
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34064
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09915
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36896
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52981
Current AP: 0.23208 AP goal: 0.23000
:::MLL 1572289772.467 eval_accuracy: {"value": 0.23207601078034795, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 389}}
:::MLL 1572289772.483 eval_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 392}}
:::MLL 1572289772.510 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1572289773.171 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '160', '--warmup', '650', '--lr', '2.92e-3', '--wd', '1.6e-4', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-10-28 07:09:39 PM
RESULT,SINGLE_STAGE_DETECTOR,,1402,nvidia,2019-10-28 06:46:17 PM
